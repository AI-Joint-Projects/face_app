{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8727042,"sourceType":"datasetVersion","datasetId":5237573}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"Hello\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-19T09:56:32.447707Z","iopub.execute_input":"2024-06-19T09:56:32.448026Z","iopub.status.idle":"2024-06-19T09:56:32.452947Z","shell.execute_reply.started":"2024-06-19T09:56:32.448001Z","shell.execute_reply":"2024-06-19T09:56:32.451926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D, BatchNormalization, Dropout, Layer\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.regularizers import l2\nimport matplotlib.pyplot as plt\n\n# Avoid OOM errors by setting GPU Memory Consumption Growth\ngpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\n\n# Path to your Data\nBASE_PATH = r'/kaggle/input/111111111111100000000000/alive'\nSUB_FOLDERS = os.listdir(BASE_PATH)\n\n# Image preprocessing\ndef preprocess_image(img_path):\n    img = load_img(img_path, target_size=(299, 299))\n    img_array = img_to_array(img) / 255.0\n    return img_array\n\n# Create triplets\ndef create_triplets(sub_folders, base_path):\n    triplets = []\n    for anchor_folder in sub_folders:\n        anchor_images = os.listdir(os.path.join(base_path, anchor_folder))\n        for anchor_img in anchor_images:\n            anchor_img_path = os.path.join(base_path, anchor_folder, anchor_img)\n            \n            # Choose a random negative image from a different sub-folder\n            negative_folder = random.choice(sub_folders)\n            while negative_folder == anchor_folder:\n                negative_folder = random.choice(sub_folders)\n            negative_images = os.listdir(os.path.join(base_path, negative_folder))\n            negative_img = random.choice(negative_images)\n            negative_img_path = os.path.join(base_path, negative_folder, negative_img)\n            \n            # Choose a random positive image from the same anchor folder\n            positive_img = random.choice(anchor_images)\n            while positive_img == anchor_img:\n                positive_img = random.choice(anchor_images)\n            positive_img_path = os.path.join(base_path, anchor_folder, positive_img)\n            \n            triplets.append([anchor_img_path, positive_img_path, negative_img_path])\n    \n    print(f\"Created {len(triplets)} triplets\")\n    return np.array(triplets)\n\n# Load images on the fly\ndef load_image(img_path):\n    return preprocess_image(img_path)\n\n# Create tf.data.Dataset\ndef triplet_generator(triplets):\n    for triplet in triplets:\n        anchor_img = load_image(triplet[0])\n        positive_img = load_image(triplet[1])\n        negative_img = load_image(triplet[2])\n        yield ({\n            'anchor': anchor_img,\n            'positive': positive_img,\n            'negative': negative_img\n        }, [0.0])  # Dummy label\n\nbatch_size = 8  # Batch size\n\n# Embedding Model with InceptionV3\ndef make_embedding():\n    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n    base_model.trainable = False  # Freeze base model\n\n    model = Sequential([\n        base_model,\n        GlobalAveragePooling2D(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.4),\n        Dense(128, activation='tanh', kernel_regularizer=l2(0.01)),\n        BatchNormalization(),\n        Dropout(0.3)\n    ])\n    return model\n\n# Custom layer for concatenation and distance calculation\nclass TripletConcatenateLayer(Layer):\n    def call(self, inputs):\n        anchor, positive, negative = inputs\n        return tf.concat([anchor, positive, negative], axis=1)\n\n# Triplet Loss function\ndef triplet_loss(margin=0.35):\n    def loss(y_true, y_pred):\n        anchor, positive, negative = tf.split(y_pred, num_or_size_splits=3, axis=1)\n        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n        basic_loss = pos_dist - neg_dist + margin\n        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0))\n        return loss\n    return loss\n\nEPOCHS = 5\n\n# Function to ensure directory exists\ndef ensure_dir_exists(directory):\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n# Main training loop\n# choose number of folders to process at a time in steps_per_run\ntotal_folders = len(SUB_FOLDERS)\nsteps_per_run = 100\n\n# Create main model directory and subdirectories\n# Checkpoint, save your model here\nmodel_dir = r'/kaggle/working/'\nensure_dir_exists(model_dir)\nembedding_model_dir = os.path.join(model_dir, 'embedding')\nsiamese_model_dir = os.path.join(model_dir, 'siamese')\nkeras_model_dir = os.path.join(model_dir, 'keras')\nensure_dir_exists(embedding_model_dir)\nensure_dir_exists(siamese_model_dir)\nensure_dir_exists(keras_model_dir)\n\n# Load or create models\ndef load_or_create_model(batch_index):\n    if batch_index == 0:\n        embedding = make_embedding()\n        input_anchor = Input(shape=(299, 299, 3), name='anchor')\n        input_positive = Input(shape=(299, 299, 3), name='positive')\n        input_negative = Input(shape=(299, 299, 3), name='negative')\n        \n        embedding_anchor = embedding(input_anchor)\n        embedding_positive = embedding(input_positive)\n        embedding_negative = embedding(input_negative)\n        \n        concatenated_embeddings = TripletConcatenateLayer()([embedding_anchor, embedding_positive, embedding_negative])\n        \n        siamese_model = Model(inputs=[input_anchor, input_positive, input_negative], outputs=concatenated_embeddings)\n        siamese_model.compile(optimizer=SGD(learning_rate=0.0005, momentum=0.9), loss=triplet_loss())\n    else:\n        siamese_model = load_model(\n            os.path.join(siamese_model_dir, f'siamese_model_{batch_index}.h5'), \n            custom_objects={'loss': triplet_loss(), 'TripletConcatenateLayer': TripletConcatenateLayer}\n        )\n        embedding = siamese_model.layers[3]  # Assuming the embedding model is the third layer in the siamese model\n\n    return embedding, siamese_model\n\n# Store history of each batch\ncombined_history = {\n    'loss': [],\n    'val_loss': [],\n    'lr': []\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, total_folders, steps_per_run):\n    current_folders = SUB_FOLDERS[i:i + steps_per_run]\n    triplets = create_triplets(current_folders, BASE_PATH)\n    \n    triplet_dataset = tf.data.Dataset.from_generator(\n        lambda: triplet_generator(triplets), \n        output_signature=(\n            {\n                'anchor': tf.TensorSpec(shape=(299, 299, 3), dtype=tf.float32),\n                'positive': tf.TensorSpec(shape=(299, 299, 3), dtype=tf.float32),\n                'negative': tf.TensorSpec(shape=(299, 299, 3), dtype=tf.float32),\n            },\n            tf.TensorSpec(shape=(1,), dtype=tf.float32)  # Dummy label\n        )\n    )\n\n    triplet_dataset = triplet_dataset.shuffle(buffer_size=512).batch(batch_size).repeat().prefetch(tf.data.experimental.AUTOTUNE)\n    total_size = len(triplets)\n    train_size = int(0.8 * total_size)\n    test_size = total_size - train_size\n    steps_per_epoch = train_size // batch_size \n    validation_steps = test_size // batch_size\n\n    train_dataset = triplet_dataset.take(train_size)\n    test_dataset = triplet_dataset.skip(train_size).take(test_size)\n\n    embedding, siamese_model = load_or_create_model(i // steps_per_run)\n\n    # Callbacks\n    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n    embedding_checkpoint = ModelCheckpoint(\n        os.path.join(embedding_model_dir, f'{i//steps_per_run + 1}_embedding_model.keras'),\n        monitor='val_loss',\n        save_best_only=True,\n        verbose=1,\n        save_weights_only=False\n    )\n    print(\"on my way\")\n    history = siamese_model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=steps_per_epoch, \n                                validation_data=test_dataset, validation_steps=validation_steps, \n                                callbacks=[lr_scheduler, early_stopping, embedding_checkpoint])\n\n    print(f\"Training completed for batch {i//steps_per_run + 1}\")\n\n    model_path = os.path.join(keras_model_dir, f'siamese_model_{i//steps_per_run + 1}.keras')\n    if os.path.exists(model_path):\n        os.remove(model_path)\n\n    siamese_model.save(model_path)\n    print(f\"Model {i//steps_per_run + 1} Saved\")\n\n    model_path_h5 = os.path.join(siamese_model_dir, f'siamese_model_{i//steps_per_run + 1}.keras')\n    siamese_model.save(model_path_h5)\n    print(f\"Full Siamese model {i//steps_per_run + 1} saved as .keras file\")\n\n    embedding_model_path = os.path.join(embedding_model_dir, f'embedding_model_{i//steps_per_run + 1}.keras')\n    embedding.save(embedding_model_path)\n    print(f\"Embedding model {i//steps_per_run + 1} saved as .keras file\")\n\n    # Combine history for plotting later\n    for key in history.history.keys():\n        combined_history[key] = combined_history.get(key, []) + history.history[key]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## save and plot fig","metadata":{}},{"cell_type":"code","source":"# Save combined history\nnp.save(os.path.join(model_dir, 'combined_history.npy'), combined_history)\n\n# Plot combined history\nplt.figure(figsize=(12, 6))\nplt.plot(combined_history['loss'], label='Training Loss')\nplt.plot(combined_history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss Over Batches')\nplt.xlabel('Batch')\nplt.ylabel('Loss')\nplt.ylim(0, 800)  # Set y-axis limits for better visualization\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View embedding of a image","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}